
<!DOCTYPE html>
<html lang="en">
  <head>
  <!-- concepts taken from http://www.eng.tau.ac.il/~berman/ and http://jiahuiyu.com/ -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

    <title>Tavi Halperin</title>
    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="dist/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this page -->
    <link href="default.css" rel="stylesheet">
	
	
  </head>

  <body>
    <div class="container">

      <div class="page-header">
		<div class="row">
			<div class="col-xs-12 col-sm-8">
			  <dl>
			    <dd>
			      <table>
			        <tr>
			          <td class="profile">
			            <img class="profile" src="profile_pic.jpeg">
			          </td>
			          <td class="heading">
			            <h1>Tavi Halperin</h1>
			            Computer Vision and Deep Learning Researcher @
			            <a href="https://www.lightricks.com"> Lightricks  </a><br />
			            tavihalperin@gmail <br />
			            <a href = "http://scholar.google.co.il/citations?user=YBdcBHMAAAAJ&hl=en">Google Scholar</a>&nbsp;&nbsp;&nbsp;|
			            &nbsp;&nbsp;
			            <a href = "https://il.linkedin.com/in/tavihalperin">Linkedin</a>&nbsp;&nbsp;&nbsp;|
			            &nbsp;&nbsp;
			            <a href = "https://github.com/tavihalperin">Github</a>
			            &nbsp;&nbsp;
			          </td>
			        </tr>
			      </table>
			    </dd>
			  </dl>

			</div>
		</div>
			<p>
				As a Researcher and Team Lead at the research department of Lightricks, my primary focus lies on state-of-the-art generative image and video models, as well as their practical applications.
				<br/>

				Previously, I did a Phd in Computer Science at the Hebrew University of Jerusalem.
				My thesis was about video processing, geometry, and using deep learning to
				jointly learn from audio and video. My advisor was Prof. <a href="http://www.cs.huji.ac.il/~peleg"> Shmuel Peleg</a>. 
			</p>
      </div> <!-- class="page-header" -->
			

      <h2>Publications</h2>
		<div class="section">
    <div class="row">  <!-- temporally stable segmentation -->
        <div class="col-xs-3 frame_video">
			<a href="https://www.youtube.com/watch?v=TpbSVUITWI4">
				<video width="190" height="190" autoplay loop muted>
  					<source src="images/temporally_stable_segmentation.mp4" type="video/mp4" />
				</video>
			</a>
		</div>
        <div class="lower">
			<p class="paper-title"> Temporally stable video segmentation without video annotations</p>
			<p class="paper-authors">Aharon Azulay, <b>Tavi Halperin </b>, Orestis Vantzos, Nadav Bornstein, Ofir Bibi </p>
			<p class="paper-venue"> IEEE Winter Conference on Applications of Computer Vision (WACV) 2022 </p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/2110.08893">arXiv</a> &nbsp;
			<a href="https://www.youtube.com/watch?v=TpbSVUITWI4">video</a> &nbsp;
			</p>
		</div>
    </div>


    <div class="row">  <!-- Motion Brush -->
        <div class="col-xs-3 frame_video">
			<a href="https://pub.res.lightricks.com/endless-loops/">
				<video width="165" height="190" autoplay loop muted>
  					<source src="images/stairs.mp4" type="video/mp4" />
				</video>
			</a>
		</div>
        <div class="lower">
			<p class="paper-title">Endless Loops: Detecting and Animating Periodic Patterns in Still Images</p>
			<p class="paper-authors"> <b>Tavi Halperin</b>, Hanit Hakim, Orestis Vantzos, Gershon
				Hochman, Gal Nachmana, Netai Benaim, Lior Sassy, Michael Kupchik, Ofir Bibi, Ohad
				Fried </p>
			<p class="paper-venue"> ACM Transactions on Graphics (Proc. SIGGRAPH), 2021 </p>
			<p class="paper-links">
			<a href="https://pub.res.lightricks.com/endless-loops/">project</a> &nbsp;
			<a href="https://arxiv.org/abs/2105.09374">arXiv</a> &nbsp;
			<a href="https://www.youtube.com/watch?v=8ZYUvxWuD2Y">video</a> &nbsp;
			<a href="https://drive.google.com/file/d/1Dtq25GYPwtqXz3EF_hpKAUcLJxFgvVrq/view?usp=sharing">supplementary</a> &nbsp;
			<a href="https://apps.apple.com/us/app/enlight-pixaloop/id1381206010">mobile app</a>&nbsp;
			<a href="https://medium.com/@lightricks-tech-blog/motion-brush-a-master-stroke-for-the-creator-community-d7e6e19b6eb3">blogpost</a>&nbsp;
			</p>
		</div>
    </div>


    <div class="row">  <!-- MaskGAN -->
        <div class="col-xs-3 frame">
			<a href="https://arxiv.org/abs/1811.12739">
			<img src="images/representative_NEG.png"/></a>
		</div>
        <div class="lower">
			<p class="paper-title">Neural separation of observed and unobserved distributions</p>
			<p class="paper-authors"> <b>Tavi Halperin</b>, Ariel Ephrat and Yedid Hoshen </p>
			<p class="paper-venue"> International Conference on Machine Learning (ICML) 2019</p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/1811.12739">arXiv</a> &nbsp;
			<a href="https://github.com/tavihalperin/Neural-Egg-Seperation">code</a> &nbsp;
			</p>
		</div>
    </div> 

    <div class="row">  <!-- AV snap -->
        <div class="col-xs-3 frame">
			<a href="https://arxiv.org/abs/1808.06250"><img src="images/av_snap.jpg"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">Dynamic Temporal Alignment of Speech to Lips</p>
			<p class="paper-authors"> <b>Tavi Halperin*</b>, Ariel Ephrat* and Shmuel Peleg </p>
			<p class="paper-venue">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2019</p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/1808.06250">arXiv</a> &nbsp;
			<a href="https://github.com/tavihalperin/AV-sync">code</a> &nbsp;
			<a href="https://www.youtube.com/watch?v=t7m0yEnBG7M">video</a> &nbsp;
			
			</p>
			[*equal contribution]  
		</div>
    </div> <!-- class="row"  --> 
		  
    <div class="row">  <!-- Real time sky replacement -->
        <div class="col-xs-3 frame">
			<a href="https://arxiv.org/abs/1903.02582"><img src="images/clear_skies_ahead.jpg"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">Clear Skies Ahead: Towards Real-Time Automatic Sky Replacement in Video</p>
			<p class="paper-authors"> <b>Tavi Halperin</b>, Harel Cain, Ofir Bibi and Michael Werman</p>
			<p class="paper-venue">Eurographics 2019</p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/1903.02582">arXiv</a> &nbsp;
			<a href="https://www.youtube.com/watch?v=1uZ46YzX-pI">video</a> &nbsp;
			
			</p>
		</div>
    </div> <!-- class="row"  --> 
		  

    <div class="row">  <!-- Seeing through noise -->
        <div class="col-xs-3 frame">
			<a href="http://www.vision.huji.ac.il/speaker-separation"><img src="images/seeing_through_noise.png"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">Seeing through noise: Speaker separation and enhancement using visually-derived speech</p>
			<p class="paper-authors"> Aviv Gabbay, Ariel Ephrat, <b>Tavi Halperin</b> and Shmuel Peleg
			</p>
			<p class="paper-venue">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2018</p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/1708.06767">arXiv</a> &nbsp;
			<a href="http://www.vision.huji.ac.il/speaker-separation/">project</a> 
			&nbsp;
			<a href="https://youtu.be/qmsyj7vAzoI">video</a> &nbsp;
			
			</p>
		</div>
    </div> <!-- class="row"  --> 
		  

    <div class="row">  <!-- an epipolar line from a single pixel -->
        <div class="col-xs-3 frame">
			<a href="https://arxiv.org/abs/1703.09725"><img src="images/epipolar_single.png"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">An Epipolar Line from a Single Pixel</p>
			<p class="paper-authors"> <b>Tavi Halperin</b> and Michael Werman
			</p>
			<p class="paper-venue"> IEEE Winter Conference on Applications of Computer Vision (WACV) 2018</p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/1703.09725">arXiv</a> &nbsp;
			<a href="https://www.youtube.com/watch?v=sw6AsB0DyoA">video</a> &nbsp;
			

			</p>
		</div>
    </div> <!-- class="row"  --> 
		

    <div class="row">  <!-- vid2speech 2 -->
        <div class="col-xs-3 frame">
			<a href="http://www.vision.huji.ac.il/vid2speech"><img   src="images/overview_vid2speech.png"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">Improved Speech Reconstruction from Silent Video</p>
			<p class="paper-authors">Ariel Ephrat*, <b>Tavi Halperin*</b> and Shmuel Peleg 
			</p>
			<p class="paper-venue">ICCV Workshop on Computer Vision for Audio-Visual Media 2017</p>
			<p class="paper-links">
			<a href="https://arxiv.org/abs/1708.01204">arXiv</a> &nbsp;
			<a href="http://www.vision.huji.ac.il/vid2speech">project</a> &nbsp;
			<a href="https://www.youtube.com/watch?v=Xjbn7h7tpg0">video</a> &nbsp;
			
			</p>
			[*equal contribution]  
		</div>
    </div> <!-- class="row"  --> 
	  


    <div class="row">  <!-- panoramic egosampling -->
        <div class="col-xs-3 frame">
			<a href="http://www.vision.huji.ac.il/egosampling"><img src="images/panoramic_hyperlapse.png"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">Egosampling: Wide view hyperlapse from egocentric videos</p>
			<p class="paper-authors"> <b>Tavi Halperin</b>, Yair Poleg, Chetan Arora and Shmuel Peleg
			</p>
			<p class="paper-venue">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) 2017</p>
			<p class="paper-links">
			<a href="http://www.cs.huji.ac.il/~peleg/papers/TCSVT17-WideEgo.pdf">pdf</a> &nbsp;
			
			</p>
		</div>
    </div> <!-- class="row"  --> 
		  

    <div class="row">  <!-- Two points fundamental matrix -->
        <div class="col-xs-3 frame">
			<a href="http://www.cs.huji.ac.il/~peleg/papers/icpr16-epipolar.pdf"><img src="images/Epipolar geometry based on line similarity.png"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">Epipolar geometry based on line similarity</p>
			<p class="paper-authors"> Gil Ben-Artzi, <b>Tavi Halperin</b>, Michael Werman and Shmuel Peleg
			</p>
			<p class="paper-venue">International Conference on Pattern Recognition (ICPR) 2016</p>
			<p class="paper-links">
			<a href="http://www.cs.huji.ac.il/~peleg/papers/icpr16-epipolar.pdf">pdf</a> &nbsp;
			
			</p>
		</div>
    </div> <!-- class="row"  --> 
		

    <div class="row">  <!-- egosampling -->
        <div class="col-xs-3 frame">
			<a href="http://www.vision.huji.ac.il/egosampling"><img src="images/egosampling.png"/></a>
		</div>
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="lower">
			<p class="paper-title">EgoSampling: Fast-Forward and Stereo for Egocentric Videos</p>
			<p class="paper-authors">Yair Poleg, <b>Tavi Halperin</b>, Chetan Arora and Shmuel Peleg
			</p>
			<p class="paper-venue">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2015</p>
			<p class="paper-links">
			<a href="http://www.cs.huji.ac.il/~peleg/papers/cvpr15-egosampling.pdf">pdf</a> &nbsp;
			<a href="http://www.vision.huji.ac.il/egosampling/">project</a> &nbsp;
			<a href="https://youtu.be/vUUqydwGvi0">video</a> &nbsp;
			
			</p>
		</div>
    </div> <!-- class="row"  --> 
		  
</div>
      <h2>Patents</h2>


<div class="section">
    <div class="row">  <!-- Seeing through noise patent -->

		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="col-xs-12 col-sm-10 col-md-10">
			<p class="paper-title">Method and system for enhancing a speech signal of a human speaker in a video using visual information </p>
			<p class="paper-authors"> Shmuel Peleg, Asaph Shamir, Tavi Halperin, Aviv Gabbay, Ariel
				Ephrat
			</p>
			<p class="paper-links">
			<a href="https://patents.google.com/patent/US10475465B2/en">
			U.S. Patent 10,475,465
			</a>
			</p>

		</div>
    </div> <!-- class="row"  -->


    <div class="row">  <!-- egosampling patent -->
       
		<!--<div class="col-xs-6 col-md-0"></div>-->
        <div class="col-xs-12 col-sm-10 col-md-10">
			<p class="paper-title">Method and system for generating adaptive fast forward of egocentric videos‏ </p>
			<p class="paper-authors"> Shmuel Peleg, Yair Poleg, Tavi Halperin and Chetan Arora
			</p>
			<p class="paper-links"> 
			<a href="https://patents.google.com/patent/US20170270677A1/en">
			U.S. Patent 9,672,626
			</a>
			</p>
			
		</div>
    </div> <!-- class="row"  --> 


</div>
    </div> <!-- /container -->


    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="dist/js/ie10-viewport-bug-workaround.js"></script>
  
	<!-- Start of StatCounter Code for Default Guide -->
	<script type="text/javascript">
		var sc_project=11743178; 
		var sc_invisible=0; 
		var sc_security="1477e76f"; 
		var scJsHost = (("https:" == document.location.protocol) ?		"https://secure." : "http://www.");
		document.write("<sc"+"ript type='text/javascript' src='" +		scJsHost+"statcounter.com/counter/counter.js'></"+"script>");
	</script>
	<noscript>
		<div class="statcounter">
			<a title="Web Analytics"
			href="http://statcounter.com/" target="_blank">
			<img class="statcounter" src="//c.statcounter.com/11743178/0/1477e76f/0" alt="Web Analytics">
			</a>
		</div>
	</noscript>
	<!-- End of StatCounter Code for Default Guide -->


  </body>
</html>

